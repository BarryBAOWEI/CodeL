{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1, align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据科学引论 - Python之道 </h1>\n",
    "\n",
    "<h1, align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第9课 机器学习</h1>\n",
    "# <center>决策树</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一章你将会学习一个流行的机器学习算法-决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入指定库:\n",
    "<ul>\n",
    "    <li> <b>numpy (as np)</b> </li>\n",
    "    <li> <b>pandas</b> </li>\n",
    "    <li> <b>DecisionTreeClassifier</b> from <b>sklearn.tree</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们简单介绍一下数据集，我们使用的是一个名为skulls.csv的数据集，包括来自5个不同年代的埃及头骨的测量数据.\n",
    "\n",
    "<img src = \"https://ibm.box.com/shared/static/02z8krlr99hwrqa2ecx3ycuiwqkcuzjv.png\", align = 'left'>\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "<b>epoch</b> - 头骨的年代，分为4000BC，3300BC，1850BC，200BC和AD150等不同的年代。这些年份这是大约估算的。\n",
    "\n",
    "<b>mb</b> - 头骨最大宽度.\n",
    "\n",
    "<b>bh</b> - 头顶到颅底的高度.\n",
    "\n",
    "<b>bl</b> - 下颚到颅底的长度.\n",
    "\n",
    "<b>nh</b> - 鼻骨的高度.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_data = pandas.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/skulls.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用<b>my_data</b>读取来自skulls.csv的数据。声明以下变量\n",
    "<ul>\n",
    "    <li> <b> X </b> 作为 <b> 特征矩阵 </b> (就是my_data的数据) </li>\n",
    "\n",
    "    \n",
    "    <li> <b> Y </b> 作为 <b> 响应向量 (目标) </b> </li>\n",
    "\n",
    "    \n",
    "    <li> <b> targetNames </b>作为 <b> 响应向量名称列表(目标名称)</b> </li>\n",
    "    \n",
    "    \n",
    "    <li> <b> featureNames </b> 作为 <b> 特征矩阵列名称列表 </b> </li>\n",
    "   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得数据集的属性名列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureNames = list(my_data.columns.values)[2:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗数据集，将数据集中不包含数值的目标列和表示序号的列删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the column containing the target name since it doesn't contain numeric values.\n",
    "# axis=1 means we are removing columns instead of rows.\n",
    "X = my_data.drop(my_data.columns[[0,1]], axis=1).values\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列出不同的年代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targetNames = my_data[\"epoch\"].unique().tolist()\n",
    "targetNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将年代值放入目标向量Y中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = my_data[\"epoch\"]\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 设置决策树\n",
    "我们将从原始数据中分离出训练和测试数据。为此，我们需要借助sklearn.cross_validation的train_test_split方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> train_test_split </b> 会返回四个参数，我们将它们命名为:<br>\n",
    "X_trainset, X_testset, y_trainset, y_testset <br> <br>\n",
    "<b> train_test_split </b>需要如下参数: <br>\n",
    "X, y, test_size=0.3, and random_state=3. <br> <br>\n",
    "<b>X</b> 和 <b>y</b>表示分离之前的数据集，<b>test_size</b>表示测试数据的占比，<b>random_state</b>保证我们每次调用得到相同的分离结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出X_trainset和 y_trainset的结构，确保维度相匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#python2 print X_trainset.shape \n",
    "#python2 print y_trainset.shape\n",
    "print (X_trainset.shape) \n",
    "print (y_trainset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出X_testset 和 y_testset的结构，确保维度相匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#python2 print X_testset.shape \n",
    "#python2 print y_testset.shape\n",
    "print (X_testset.shape) \n",
    "print (y_testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将先创建DecisionTreeClassifier（决策树分类器）的实例，赋值给skullsTree。\n",
    "\n",
    "我们设置<i> criterion=\"entropy\" </i>，这样能够得到每个节点的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skullsTree = DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们用训练数据集 X_trainset 和 y_trainset 来进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skullsTree.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成的模型针对测试数据集X_testset进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predTree = skullsTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要对预测值和实际值做比较，那么可以打印出 <b>predTree</b> 和 <b>y_testset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predTree [0:5])\n",
    "print(y_testset [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，从sklearn中导入metrics，检查我们的模型的准确性 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"DecisionTrees's Accuracy: \"), metrics.accuracy_score(y_testset, predTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们可以可视化生成的决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "%matplotlib inline \n",
    "\n",
    "# for graphviz on windows\n",
    "#import os     \n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "filename = \"skulltree.png\"\n",
    "out=tree.export_graphviz(skullsTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png(filename)\n",
    "img = mpimg.imread(filename)\n",
    "plt.figure(figsize=(100, 200))\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
