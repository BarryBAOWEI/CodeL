{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1, align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据科学引论 - Python之道 </h1>\n",
    "\n",
    "<h1, align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第6课 使用Python和pandas统计入门 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1, align=\"center\">波士顿房屋数据</h1>\n",
    "\n",
    "我们将会分析波士顿的房屋数据，数据将包括：\n",
    " \n",
    "1) Age: 1940年之前在每个城镇建立的自有住房的比例\n",
    "\n",
    "2) MV: 每个城镇的房价中位数（单位是$1000）\n",
    "\n",
    "我们将计算平均数、中位数、标准差，来分析不同城镇内的房屋情况。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2, align=center>获得数据</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用下面的链接直接下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linux !wget --output-document /resources/data/ageprice.csv https://ibm.box.com/shared/static/05u2mb2x4n9ak8gffmnelydx0ibdeqzh.csv\n",
    "# 自行下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入所需的依赖库：pandas，matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果这段发生错误No module named 'seaborn'，则解注释下列这句话先安装一下这个库，以管理员权限在命令行中输入“conda install seaborn”安装seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个帮助函数涵盖了正太分布和直方图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalandHistogram( DataFrame):\n",
    "    \n",
    "    mu=DataFrame.mean()\n",
    "    sigma=DataFrame.std()\n",
    "    x=DataFrame.values.flatten()\n",
    "       # the histogram of the data\n",
    "    n, bins, patches = plt.hist(x, 10, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "    # add a 'best fit' line\n",
    "    y = mlab.normpdf( bins, mu, sigma)\n",
    "    l = plt.plot(bins, y, 'r--', linewidth=1)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Probability')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用`pd.read_csv`读取数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'resources/data/AgePrice.csv' does not exist: b'resources/data/AgePrice.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7463d18c77c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"resources/data/AgePrice.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'resources/data/AgePrice.csv' does not exist: b'resources/data/AgePrice.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"resources/data/AgePrice.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1, align=center>数据清洗</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除额外的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用head方法展示前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1, align=center> 统计分析  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "1) 计算下列平均值：\n",
    "a) 1940年之前房屋建造的比例\n",
    "b) 房屋的价值   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 计算中位数，统计内容同上   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 计算标准差，内容同上:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) 计算最大和最小值，内容同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) 使用__describe__方法得到总结。\n",
    "\n",
    "这个方法会展示以下结果：\n",
    "- 数据条数\n",
    "- 平均值, \n",
    "- 标准差, \n",
    "- 最小值, \n",
    "- IQR (分位点: 25%, 50% and 75%) \n",
    "- 最大值.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1, align=center> 直方图</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5) 使用直方图展示每个城镇AGE的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AGE\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) 使用直方图展示每个城镇MV的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MV\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1, align=center> 概率质量函数和正态分布 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率质量函数和正态分布可以帮助你轻松地从整体上理解你的数据，并度量它们的属性 \n",
    "\n",
    "假设我们要得到以下的值：\n",
    "\n",
    "在波士顿，房屋具有20年房龄的概率是多少？\n",
    "在波士顿，房屋具有30年房龄的概率是多少？\n",
    "\n",
    "我们可以用 P(X = 20)或 P(X = 30)来表示.这个概率函数表示一间位于波士顿的随机选中的房屋X，对特定的房龄值x，其房龄等于x的概率是多大？这个概率可以用函数f(x)表示，它被称为概率质量函数（__probability mass function__）. \n",
    "\n",
    "__注意 1:__ P(X = 1) + P(X = 2)+ .. +P(X = 100) = 1   \n",
    "__注意 2:__ 如果可选值是连续（非离散）的话，我们需要使用概率密度函数 （__probability density function__）, \n",
    "\n",
    "现在让我们将数据的概率密度函数与正态分布在图形上作些比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  波士顿AGE的分布是正态分布吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=df['AGE'].mean()\n",
    "sigma=df['AGE'].std()\n",
    "x=df['AGE'].values.flatten() #actual values of age of the houses\n",
    "\n",
    "# the parameters of histogram of the data\n",
    "# 10 is number of bins\n",
    "# normed = 1, means the histogram is normalized\n",
    "n, bins, patches = plt.hist(x, 10, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = mlab.normpdf( bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据没有呈现出一个中间钟型的凸起，所以不是正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 波士顿MV的分布是正态分布吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=df['MV'].mean()\n",
    "sigma=df['MV'].std()\n",
    "x=df['MV'].values.flatten() #actual values of age of the houses\n",
    "\n",
    "# the parameters of histogram of the data\n",
    "# 10 is number of bins\n",
    "# normed = 1, means the histogram is normalized\n",
    "n, bins, patches = plt.hist(x, 10, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = mlab.normpdf( bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从形状上看是的。\n",
    "\n",
    "通过图去观察数据是十分实用的。通过图，我们还能回答关于区间的问题，比如价格在10k到15k之间的概率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索： 总览、统计、分组、箱线图 和 相关性\n",
    "让我们加载另一个数据集\n",
    "\n",
    "####  数据集\n",
    "\n",
    "数据源: https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "\n",
    "#### 数据集信息:\n",
    "这个数据源包括三种不同类型的实体：(a)关于汽车各种属性的规格说明，(b) 汽车被指定的保险风险等级，（c）与其他汽车相比的规格化的损赔。\n",
    "第二个实体所表示的等级对应的是汽车相对于其价格而言风险更大的程度。汽车最初被赋予的风险等级与其价格相关，如果之后发现其风险更大或者更小，这个等级就会相应地向上或向下调整。例如，等级为+3就表示是该车风险较大，-3表示该车比较安全。\n",
    "第三个实体所表示的因素是每个被保险车辆年的相对平均损赔。这个值是在特定的尺寸分类(双门小型车、旅行车、运动型/专业型车，等等)下的所有汽车中规格化的值，表示每辆车每年的平均损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "# read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "\n",
    "#linux !wget --output-document /resources/data/df-Automobile-cleaned.csv https://ibm.box.com/shared/static/uxc0it2dyu0ecrw14aoj9yspz8gh446r.csv\n",
    "#自行下载    \n",
    "#linux df = pd.read_csv(\"/resources/data/df-Automobile-cleaned.csv\")\n",
    "df = pd.read_csv(\"resources/data/df-Automobile-cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总览\n",
    "使用describe方法得到一个大致的总览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics using pandas method\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想得到特定的一些列的汇总结果呢（比如值是字符串的）？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计数:\n",
    "我们还可以使用__value-counts__方法得到每个属性/变量有几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive-wheels as variable\n",
    "drive_wheels_counts = df['drive-wheels'].value_counts().to_frame()\n",
    "drive_wheels_counts.rename(columns={'drive-wheels': 'value_counts'}, inplace=True)\n",
    "drive_wheels_counts.index.name = 'drive-wheels'\n",
    "drive_wheels_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine-location as variable\n",
    "engine_loc_counts = df['engine-location'].value_counts().to_frame()\n",
    "engine_loc_counts.rename(columns={'engine-location': 'value_counts'}, inplace=True)\n",
    "engine_loc_counts.index.name = 'engine-location'\n",
    "engine_loc_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现只有3辆车是后置发动机，191辆是前置发动机，数据倾斜过于严重，所以从发动机位置这个角度去判断价格是不太合理的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分组:\n",
    "另一个观察数据的方法是分组：\n",
    "\n",
    "groupby函数可以根据某一列的值进行分组，然后进行统计。这将方便我们观察某一个变量对另外一个变量的影响。\n",
    "\n",
    "你可以按一个变量分组，例如按\"drive-wheels\"分组，会发现一共有三组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drive-wheels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想知道哪种驱动方式最值钱，我们可以统计每个分类下的价格平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping results\n",
    "df_group_one=df[['drive-wheels','body-style','price']]\n",
    "df_group_one=df_group_one.groupby(['drive-wheels'],as_index= False).mean()\n",
    "df_group_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "通过数据，我们发现4轮驱动和前轮驱动基本价格相似，但是后轮驱动明显更贵。\n",
    "\n",
    "同样你可以同时按多个变量分组，比如\"drive-wheels\" 和 \"body-style\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping results\n",
    "df_gptest=df[['drive-wheels','body-style','price']]\n",
    "grouped_test1=df_gptest.groupby(['drive-wheels','body-style'],as_index= False).mean()\n",
    "grouped_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表格数据看起来有点累，如果我们把它们放进一个数据透视表会看得更加清楚。现在让我们使用pivot函数去创建一个数据透视表，我们把drive-wheel当成行变量，body-style作为列变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pivot=grouped_test1.pivot(index='drive-wheels',columns='body-style')\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，表格的一些格子中没有数据（NaN），我们可以通过用0填充的方法解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pivot=grouped_pivot.fillna(0) #fill missing values with 0\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 箱线图:\n",
    "\n",
    "使用箱线图是一种不错的用来观察某一类的数据的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body-style\n",
    "sns.boxplot(x=\"body-style\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现在不同 body-style分类下的价格分布重叠太多，所以body-style不是一个值得研究的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine-location\n",
    "sns.boxplot(x=\"engine-location\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们发现根据engine-location的价格分布比较适合做价格预测。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive-wheels\n",
    "sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的，发现根据drive-wheels的价格分布比较适合做价格预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**相关性**: 相关性是一个测量不同变量之间是否独立的统计度量。 \n",
    "\n",
    "**因果关系**: 两个变量之间的因果关系。\n",
    "\n",
    "需要注意的是，相关性与因果关系是不同的概念。如前所述，数据科学更加适合探索数据相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们检测下engine-size和price的相关性\n",
    "\n",
    "我们使用下列散点分析命令来可视化两个变量，并且添加一个回归线。\n",
    "我们可以使用seaborn的regplot()命令来显示散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"engine-size\", y=\"price\",data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正线性相关: \n",
    "engine-size的增大会导致价格的增大。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 负相关关系\n",
    "让我们查看一下highway-mpg与price的关系：\n",
    "\n",
    "highway-mpg的增加会导致价格的降低。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"highway-mpg\", y=\"price\",data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 弱线性关系\n",
    "\n",
    "Peak-rpm看上去就和price没什么关系了，回归线几乎是平的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak rpm as a predictor variable of price\n",
    "sns.regplot(x=\"peak-rpm\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 所有变量之间的相关性如何呢?\n",
    "\n",
    "现在的问题是：“哪个属性是最主要的影响价格的因素”\n",
    "\n",
    "我们之前的问题都是针对某一个变量对价格影响如何，现在让所有变量都对price来一次相关性检测。可以使用corr方法来简单完成这个功能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们发现了是__engine-size__ ，且他的相关系数为0.888745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 什么是相关系数?\n",
    "\n",
    "相关性（皮尔逊相关）表示了变量X和Y之间的线性依赖程度。结果在-1到1之间。\n",
    "- **1**: 完全正相关\n",
    "- **0**: 没有线性关系\n",
    "- **-1**: 完全负相关 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 高的相关系数是否就说明了两个变量十分相关？ \n",
    "\n",
    "除了相关系数，我们还可以看 __p-vaue__。P-value帮助我们确认找的相关系数是否可信。\n",
    "\n",
    "**什么是 P-value?**:  \n",
    "P-value是两个变量之间相关性是否显著的概率。通常地，我们把0.05设为一个显著水平，也就是说这个相似性有95%的置信度。\n",
    "\n",
    "大致地：\n",
    "- p-value<0.001 我们认为相关性十分可信\n",
    "- p-value<0.05, 我们认为相关性比较可信\n",
    "- p-value<0.1, 我们认为相关性不太可信\n",
    "- p-value>0.1, 我们认为相关性不可信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['horsepower'], df['price'])\n",
    "#python2 print \"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value   \n",
    "print (\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结论:\n",
    "horsepower和price的相关性中，线性相关性比较高(~0.809, 接近1)，p-value小于0.001的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 那么三组数据之间或者不同的大小的相关性如何?\n",
    "\n",
    "我们在这个场合使用透视表，我们的变量是Drive Wheels和Body Style。我们需要找到这两个变量和price的关系。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots()\n",
    "im=ax.pcolor(grouped_pivot, cmap='RdBu')\n",
    "\n",
    "#label names\n",
    "row_labels=grouped_pivot.columns.levels[1]\n",
    "col_labels=grouped_pivot.index\n",
    "#move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(grouped_pivot.shape[1])+0.5, minor=False)\n",
    "ax.set_yticks(np.arange(grouped_pivot.shape[0])+0.5, minor=False)\n",
    "#insert labels\n",
    "ax.set_xticklabels(row_labels, minor=False)\n",
    "ax.set_yticklabels(col_labels, minor=False)\n",
    "#rotate label if too long\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类离散变量和连续变量之间的关系\n",
    "\n",
    "比入drive-wheels和price之间的关系是什么？\n",
    "\n",
    "我们可以使用ANOVA测试去计算它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df[['drive-wheels','price']]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们在上述两列里面跑测试，如果价格在不同的drive-wheels类别表现出巨大差异，那么drive-wheels就是高度相关的。ANOVA测试会返回一个大的F-test分数和一个小的p-value\n",
    "\n",
    "\n",
    "#### ANOVA: 方差分析\n",
    "这是一个统计学方法，用于测试两组数据的平均值是否有明显的不同。返回两个值\n",
    "\n",
    "**F-测试分数**: ANOVA假设所有组别的平均值是相同的，计算实际与预期的偏差有多大。其偏差越大，F-test分数越大。 \n",
    "\n",
    "**P-值 **: 与之前的相关系数置信度相同，就是表示F-测试分数的可信程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rwd = df[df['drive-wheels']=='rwd']['price']\n",
    "df_fwd = df[df['drive-wheels']=='fwd']['price']\n",
    "df_4wd = df[df['drive-wheels']=='4wd']['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val, p_val = stats.f_oneway(df_rwd, df_fwd, df_4wd)\n",
    "#python2 print \"ANOVA results: F=\", f_val, \", P =\", p_val   \n",
    "print (\"ANOVA results: F=\", f_val, \", P =\", p_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果非常棒，也就是 F test很大，然后p-value几乎为0，这表示__drive-wheels和price强相关__，具有几乎确定的统计显著性。\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
